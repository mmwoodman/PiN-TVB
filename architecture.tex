TVB is logically and technically divided into a scientific
library and a framework package, where the scientific library includes
datatypes, basic analyses and the simulator, while the
framework handles execution infrastructure, the web-based user interface and
data storage.  The scientific library can function as an independent Python
module, but the framework depends the scientific library for datatype definitions
and algorithms. 

\subsection{Basic Concepts}

The TVB framework is oriented around data and the operations that introduce,
generate, transform and visualize the data. The relevant interface classes
derive from the metaclasses in Python's abstract base class library, and
provide a foundation for defining any type of data from a tuple to a
set of EEG channel labels to a simulation, each of which is defined by a class
implemented the datatype interface and possessing one or more datatypes as 
attributes. An operation is an execution of any algorithm that
has been \emph{adapted} to the framework in a class implementing the abstract
adapter interface, and range from the simulator to data importers to
visualizers.  The goal of these twin, generic abstractions is to provide a
solid basis on which to implement a storage back-end, workflow management and a
number of features to support collaborative work. 

Importantly, the framework supports both the use of the web-based graphical
interface and the console interface for advanced user and developers. Where
the console user does not wish to rely on the database persistence, this 
storage layer can be disabled. Specifically, TVB uses the notion of \emph{profile} to 
identify in what context the application is currently running,
and thus what components are expected to be loaded.
For example, when the scientific library is used alone, a specific profile (\emph{library profile}) class 
gets linked as current profile, which, in this case, disables data storage and the web interface. Other profiles available
in TVB are: \emph{command profile}, \emph{deployment profile} (with web interface), and \emph{test profiles}.


%\begin{verbatim}
%    def configure(self, **kwargs):
%        To be implemented in each Adapter that requires any specific configurations
%        before the actual launch.
%
%    def get_input_tree(self):
%        Describes inputs and outputs of the launch method.
%
%    def get_output(self):
%        Describes inputs and outputs of the launch method.
%
%    def get_required_memory_size(self, **kwargs):
%        Abstract method to be implemented in each adapter. Should return the required memory
%        for launching the adapter.
%
%    def get_required_disk_size(self, **kwargs):
%        Abstract method to be implemented in each adapter. Should return the required memory
%        for launching the adapter in kilo-Bytes.
%
%    def get_execution_time_approximation(self, **kwargs):
%        Method should approximate based on input arguments, the time it will take for the operation 
%        to finish (in seconds).
%
%    def launch(self):
%         To be implemented in each Adapter.
%         Will contain the logic of the Adapter.
%         Any returned DataType will be stored in DB, by the Framework.
%\end{verbatim}


\subsection{Datatypes and storage}

\subsubsection{TVB Traits}

Because an explicit goal of TVB was to provide a user interface to each of the
entities and algorithms contained within, it is necessary at some point to
provide metadata on how to built that interface. A traits system was
developed, similar to that of IPython or EPD, allowing for
attributes on a TVB class to be written out with its full metadata. An extensive
set of building blocks are already implements from numeric types and arrays to
lists, tuples, string, and dictionaries.

When methods of such a class with annotated attributes are invoked, they may use
the traited attributes directly, accessing either a default value or one given
during the instantiation of the object. Additionally, this allows the web-based
user interface to introspect a class for all of its attributes and their
descriptions, to provide help and choose the proper display form. The explicit
typing also allows such classes to be nearly automatically mapped to storage
tables, providing persistence, when the storage layer is enabled.  Lastly,
because such metadata is used to build the docstring of a class, the console
user also may obtain extensive descriptions of class, attributes, methods and
arguments in the usual way. Table \ref{tab:traits} lists the various parts 
of a traited attribute and how they are used. 

\begin{center}
	\begin{table*}[ht]
  	\label{tab:traits}
  	\caption{TVB currently available Traited Attributes}

	\begin{tabularx}{\textwidth}{lll}
      		\toprule
      		Traited Attribute    & Description  \\ 
      		\midrule
		default 	& Default value for current attribute. Will be set on any new instance if not specified otherwise in the constructor.  \\
		console\_default & Define how a default value can be computed for current attribute, when console interface is enabled. \\
		range	& Specify the set of accepted values for current attribute. Mark that this attribute is usable for parameter space exploration. \\

		label		& Short text to be displayed in UI, in front of current attribute. \\
		doc		& Longer description for current attribute. To be displayed in UI as help-text. \\
		required	& Mark current attribute as required for when building a new instance of the parent class. \\
		locked	& When present and \emph{True}, current attribute will be displayed as read-only in the web interface. \\

		options	& Used for attributes of type \emph{Enumerate}, specifying the accepted options as a list of strings. \\
		filters\_ui	& Object relational filters on attributes, to be applied before displaying data in UI. \\
		select\_multiple & When \emph{True}, current attribute will be displayed as a select with multiple options in UI (default is single-select) \\
		order	& Optional number identifying the index at which current attribute will be displayed in UI. \\
				& When negative, the attribute is not displayed at all. Ascending order for indices is considered when displaying. \\

		use\_storage	& When \emph{False}, current attribute is not stored in database or file storage. \\
		file\_storage	& Valid values for this attribute are: \emph{None} , \emph{HDF5}, or  \emph{expandable\_HDF5}, \\
					& When \emph{None}, current attribute is not stored in the file-storage at all. When \emph{HDF5}, we use regular H5 file storage. \\
					& When \emph{expandable\_HDF5} value is set, a H5 stored in chunks is used. \\
		\bottomrule
    	\end{tabularx}
	\end{table*}
\end{center}


\subsubsection{Datatypes}

In scientific Python code, it is conventional to provide arguments
of an algorithm as a ``bare'' array or collection there of, and sanity
checks of arguments proceed on the basis of array geometry, for example.
In TVB, we consider a \textit{DataType} to be a full, formal description of 
an entity involved in an algorithm that would be part of TVB. 

In TVB, datatypes represent the common language, to be used between different
application parts: like uploaders, analyzers, simulator and visualizers.
Some of the algorithms are producing these DataTypes, while others are reading
them as input.  In order to decouple the definition and several usages of such
entities, DataTypes are declared outside the algorithms and shared between them.
For example an instance of datatype TimeSeriesRegion is created by the
Simulator, and it can be accepted as input for several visualizers or analyzed
by PCA and Cross Coherence algorithms.

Technically, TVB datatypes are annotated Python classes, which
contain one or more fields and associated descriptive information, as
well as methods for operating on the data they contain. The definition of a
datatype is achieved using TVB's traiting system, mentioned in previous section.

For example, the \texttt{Connectivity} DataType, which may elsewhere
be represented by a simple $N$ by $N$ NumPy array, is written as a class
in which one of the attributes, \texttt{weights}, is a explicitly typed 
\texttt{FloatArray}, and the declaration of this type is complemented by
explicit label, default values, and documentation strings. See
Code~\ref{lst:ConnectivityData}.

\begin{lstlisting}[caption={The Connectivity Datatype definition},
                   label={lst:ConnectivityData}]
class ConnectivityData(MappedType):

  region_labels = arrays.StringArray( 
	label="Region labels", 
        doc="""Labels for the regions ...""")

  weights = arrays.FloatArray( 
	label="Connection strengths",
        doc="""... strength of connections ...""")

  tract_lengths = arrays.FloatArray( 
	label="Tract lengths",
        doc="""... length of myelinated fibre tracts.""")

   speed = arrays.FloatArray( 
	label="Conduction speed", 
	default=numpy.array([3.0]), 
	file_storage=core.FILE_STORAGE_NONE,
         doc="""... matrix of conduction speeds ...""")

  centres = arrays.PositionArray( 
	label="Region centres",
        doc="""... locations for the region centers""")
\end{lstlisting}
	

\subsection{Adapters}

The framework expects algorithms to be adapted by providing a class
which inherits from the base adapter, \texttt{ABCAdapter}, implementing 
the adapter interface:

\begin{lstlisting}[caption={The ABCAdapter listing},
                   label={lst:ABCAdapter}]
class AdapterExample(ABCAdapter):

  @abstractmethod
  def get_input_tree(self):
  	pass

  def configure(self, **kwargs):
  	pass

  @abstractmethod
  def launch(self):
  	pass
\end{lstlisting}

\noindent where \texttt{get\_input\_tree} builds a dictionary of input
arguments required for the algorithm and for
presenting menus and fields in the user interface, \texttt{configure} allows the 
adapter to intialize itself and its algorithm based on arbitrary arguments
and \texttt{launch} invokes the algorithm.
Additional usefull methods include \texttt{get\_output}, \texttt{get\_required\_memory\_size},
\texttt{get\_required\_disk\_size}, and \texttt{get\_execution\_time\_approximation}.

Several categories of adapters have been defined in TVB: 

\begin{itemize}
	\item \textit{creators} which are internal algorithms for producing datatype instances. 
		Each creator has one or multiple pages in the web interface, in which the user
		 configures input parameters and chooses from the available options for computing a particular datatype.

	\item \textit{uploaders}: allow the upload into TVB framework of external data, 
    		such as \emph{gifti} files of plain \emph{csv} files.

	\item \textit{simulator} is an adapter for the simulator, adjusting it to fit
		the workflow mechanisms inside the framework .

	\item \textit{analyzers} which offer the interface to libraries containing algorithms 
		for the analysis of the data (wavelets, FastICA, BCT, etc).

	\item \textit{visualizers}, derived from the \emph{ABCDisplayer} base class, prepare a datatype
		for display. Each visualizer (Python adapter class) requires a complementary set
		of JS and HTML files. 

	\item \textit{portlets} provide a chain of analyzers leading to a visualizer.

	\item \textit{exporters} prepare a datatype for export \& download.

\end{itemize}

Note that the adapters and datatypes are intended to provide full 
power and flexibility of the framework; when the simulator is invoked from
the web-based UI, it is done so through a \texttt{SimulatorAdapter} which,
despite being relatively complex, is built with \emph{traits} all the way down.

It is reasonable to ask what such a scheme offers over the more 
conventional approach of Python, where presumably it would have been
sufficient that each adapter consist of a class with an \texttt{\_\_init\_\_}
and \texttt{\_\_call\_\_} method, in the case of a function type. 
We note that because in the case of TVB, the context in which an object
is used is more varied, e.g. not simply initialized but loaded through 
SqlAlchemy's ORM, and that the adapter is required to perform more tasks
than just initialization and invocation, e.g. provide expected shape of 
result, estimate occupied memory and do not start if insufficient resources are found on current machine,
 it was advantageous to create a distinct set of interfaces built on top of
the abstract base class framework provided by Python's standard library.

\paragraph{An adapter for FastICA}

An example of an adapter applying the FastICA algorithm to each of the 
state variables in a simulation time series is given in Code \ref{lst:ica}.

\lstinputlisting[caption={ICA adapter for FastICA library},
                 label={lst:ica}]{ica_adapter.py}

\paragraph{Interfacing with MATLAB}

One of the well-known libraries for characterizing anatomical 
and functional connectivity is the \emph{Brain Connectivity Toolbox} 
\citep{Rubinov_2010}. 
Because it is written in MATLAB, with maintainers who prefer MATLAB, we 
chose not to port routines of the library to Python but instead build
a MATLAB adapter which runs arbitrary MATLAB code. 

This generic Matlab adapter works by generating at runtime a script with MATLAB code, 
wrapping the script call in Python with a try-except clause,  
loading and saving the workspace before and after the call,
generating a workspace \texttt{.mat} file, invoking the MATLAB or Octave
executable, and loading the resulting workspace file. 

Despite invocation of MATLAB being a relatively slow operation, this works
without problems in a single user situation, and where Octave is available, it
is quite fast. In the case that many operations are necessary, they can be
batched into the same run.
